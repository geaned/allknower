{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "556f127b-24b7-496d-8f2d-f84687f3b0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import ir_datasets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "os.environ[\"IR_DATASETS_HOME\"] = \"/storage/kliffeup/kliffeup/allknower_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "35e86bc2-4a98-49ec-8cc3-b7f76e183363",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PREFIX = \"wikir\"\n",
    "DATASET_VERSION = \"en78k\"\n",
    "STAGE = \"training\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "17926734-ca19-41ca-85c4-aa61ca4bfbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "wikir_dataset = ir_datasets.load(f\"{DATASET_PREFIX}/{DATASET_VERSION}/{STAGE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67e34ac8-30a8-4ae4-b9ad-f58a03815df9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('doc_id', 'text')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wikir_dataset.docs_cls()._fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "727bd115-ca4f-43f5-97eb-c5c6acb61bee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GenericDoc(doc_id='1781133', text='it was used in landing craft during world war ii and is used today in private boats and training facilities the 6 71 is an inline six cylinder diesel engine the 71 refers to the displacement in cubic inches of each cylinder the firing order of the engine is 1 5 3 6 2 4 the engine s compression ratio is 18 7 1 with a 4 250 inch bore and a 5 00 inch stroke the engine weighs and is 54 inches long 29 inches wide and 41 inches tall at 2 100 revolutions per minute the engine is capable of producing 230 horse power 172 kilowatts v type versions of the 71 series were developed in 1957 the 6 71 is a two stroke engine as the engine will not naturally aspirate air is provided via a roots type blower however on the 6 71t models a turbocharger and a supercharger are utilized fuel is provided by unit injectors one per cylinder the amount of fuel injected into the engine is controlled by the engine s governor the engine cooling is via liquid in a water jacket in a boat cool external water is pumped into the engine')\n",
      "GenericDoc(doc_id='2426736', text='after rejecting an offer from cambridge university she moved to london in 1954 working in a mayfair advertising agency while moonlighting as a hat check girl in the night club le club contemporain while working at the royal college of art she met the painter frank bowling when he was still a student there they married in 1960 and had one son kitchen was one of the women interviewed by nell dunn in talking to women 1965 after divorcing bowling in the late sixties kitchen went on to live with and later marry the writer dulan barber continuing to write novels she also began writing non fiction with biographies of patrick geddes and gerard manley hopkins in later life she bought a house in barnwell northamptonshire which became the subject of her book of the same name she died on 23 november 2005 the novelist bessie head was a close friend the pair corresponded from 1969 until head s death in 1986 on a range of subjects including head s novel a question of power')\n"
     ]
    }
   ],
   "source": [
    "for doc in wikir_dataset.docs_iter()[:2]:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d60459a2-d9da-4a35-a4be-9451195d682c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GenericQuery(query_id='123839', text='yanni')\n",
      "GenericQuery(query_id='188629', text='k pop')\n",
      "GenericQuery(query_id='13898', text='venice film festival')\n",
      "GenericQuery(query_id='316959', text='downtown brooklyn')\n",
      "GenericQuery(query_id='515031', text='pennsylvania house of representatives')\n"
     ]
    }
   ],
   "source": [
    "query_idx = -1\n",
    "\n",
    "for query in wikir_dataset.queries_iter():\n",
    "    query_idx += 1\n",
    "    if query_idx >= 5:\n",
    "        break\n",
    "    print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e22622a-b224-4f11-b67b-8359feac4d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrecQrel(query_id='123839', doc_id='123839', relevance=2, iteration='0')\n",
      "TrecQrel(query_id='123839', doc_id='1793430', relevance=1, iteration='0')\n",
      "TrecQrel(query_id='123839', doc_id='806300', relevance=1, iteration='0')\n",
      "TrecQrel(query_id='123839', doc_id='806075', relevance=1, iteration='0')\n",
      "TrecQrel(query_id='123839', doc_id='836567', relevance=1, iteration='0')\n"
     ]
    }
   ],
   "source": [
    "qrel_idx = -1\n",
    "\n",
    "for qrel in wikir_dataset.qrels_iter():\n",
    "    qrel_idx += 1\n",
    "    if qrel_idx >= 5:\n",
    "        break\n",
    "    print(qrel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "304e544c-cf54-4b4f-b629-e3d879b5388a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GenericScoredDoc(query_id='123839', doc_id='806300', score=20.720094194011075)\n",
      "GenericScoredDoc(query_id='123839', doc_id='123839', score=19.91782871489318)\n",
      "GenericScoredDoc(query_id='123839', doc_id='836567', score=18.824522997710037)\n",
      "GenericScoredDoc(query_id='123839', doc_id='806326', score=18.824522997710037)\n",
      "GenericScoredDoc(query_id='123839', doc_id='806075', score=17.246712972547066)\n"
     ]
    }
   ],
   "source": [
    "bm25_score_idx = -1\n",
    "\n",
    "for bm25_score in wikir_dataset.scoreddocs_iter():\n",
    "    bm25_score_idx += 1\n",
    "    if bm25_score_idx >= 5:\n",
    "        break\n",
    "    print(bm25_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62729bc5-43e8-49a4-8824-c17454dedbba",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0026a2d-a58f-4823-86dd-1852a68ac32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_RELEVANCE = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bcb97dc1-e4ce-48df-8a5b-56f6dbd025d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = pd.DataFrame(\n",
    "    sorted(\n",
    "        map(\n",
    "            lambda item: (int(item.query_id), item.text),\n",
    "            wikir_dataset.queries_iter()\n",
    "        )  \n",
    "    ),\n",
    "    columns=[\"query_id\", \"query\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e7985a6-2f40-484b-9b70-b5c1e7ad1486",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = pd.DataFrame(\n",
    "    sorted(\n",
    "        map(\n",
    "            lambda item: (int(item.doc_id), item.text),\n",
    "            wikir_dataset.docs_iter()\n",
    "        ),\n",
    "        key=lambda item: item[0]\n",
    "    ),\n",
    "    columns=[\"doc_id\", \"doc\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37816148-fac7-4232-a731-97abd1713a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_id_to_doc_id_rels = pd.DataFrame(\n",
    "    sorted(\n",
    "        map(\n",
    "            lambda item: (int(item.query_id), int(item.doc_id), item.relevance / MAX_RELEVANCE),\n",
    "            wikir_dataset.qrels_iter()\n",
    "        ),\n",
    "        key=lambda item: (item[0], item[1])\n",
    "    ),\n",
    "    columns=[\"query_id\", \"doc_id\", \"relevance\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c36f5e2-1fda-4d32-b345-da226237908e",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_id_to_doc_id_bm25_scores = pd.DataFrame(\n",
    "    sorted(\n",
    "        map(\n",
    "            lambda item: (int(item.query_id), int(item.doc_id), item.score),\n",
    "            wikir_dataset.scoreddocs_iter()\n",
    "        ),\n",
    "        key=lambda item: (item[0], item[1])\n",
    "    ),\n",
    "    columns=[\"query_id\", \"doc_id\", \"bm25_score\"],    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0783503a-f71a-4f20-8055-507342730bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = query_id_to_doc_id_bm25_scores\\\n",
    ".merge(query_id_to_doc_id_rels, how=\"outer\")\\\n",
    ".merge(queries, how=\"left\")\\\n",
    ".merge(docs, how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cca4bf66-5acf-41ef-8c64-209020f75ca6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>bm25_score</th>\n",
       "      <th>relevance</th>\n",
       "      <th>query</th>\n",
       "      <th>doc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>79</td>\n",
       "      <td>79</td>\n",
       "      <td>16.106074</td>\n",
       "      <td>1.0</td>\n",
       "      <td>actinopterygii</td>\n",
       "      <td>these actinopterygian fin rays attach directly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>79</td>\n",
       "      <td>12139</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>actinopterygii</td>\n",
       "      <td>even the acts of launching discharging artille...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>79</td>\n",
       "      <td>34714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>actinopterygii</td>\n",
       "      <td>state of nebraska as of the 2010 united states...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>79</td>\n",
       "      <td>57100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>actinopterygii</td>\n",
       "      <td>as of the 2010 united states census the cdp s ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>79</td>\n",
       "      <td>92466</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>actinopterygii</td>\n",
       "      <td>its lyrics were written by the buenos aires bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185921</th>\n",
       "      <td>2433785</td>\n",
       "      <td>2433250</td>\n",
       "      <td>13.206970</td>\n",
       "      <td>0.5</td>\n",
       "      <td>dhanbad sadar subdivision</td>\n",
       "      <td>one of the many spurs of pareshnath hill 1 365...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185922</th>\n",
       "      <td>2433785</td>\n",
       "      <td>2433522</td>\n",
       "      <td>15.420900</td>\n",
       "      <td>0.5</td>\n",
       "      <td>dhanbad sadar subdivision</td>\n",
       "      <td>the damodar river the most important river of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185923</th>\n",
       "      <td>2433785</td>\n",
       "      <td>2433549</td>\n",
       "      <td>9.231121</td>\n",
       "      <td>0.5</td>\n",
       "      <td>dhanbad sadar subdivision</td>\n",
       "      <td>while the damodar flows along the southern bou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185924</th>\n",
       "      <td>2433785</td>\n",
       "      <td>2433785</td>\n",
       "      <td>37.233094</td>\n",
       "      <td>1.0</td>\n",
       "      <td>dhanbad sadar subdivision</td>\n",
       "      <td>initially the district was split into two subd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185925</th>\n",
       "      <td>2433785</td>\n",
       "      <td>2454548</td>\n",
       "      <td>9.047330</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dhanbad sadar subdivision</td>\n",
       "      <td>geographically garalbari is located in the lat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>185926 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        query_id   doc_id  bm25_score  relevance                      query  \\\n",
       "0             79       79   16.106074        1.0             actinopterygii   \n",
       "1             79    12139    0.000000        NaN             actinopterygii   \n",
       "2             79    34714    0.000000        NaN             actinopterygii   \n",
       "3             79    57100    0.000000        NaN             actinopterygii   \n",
       "4             79    92466    0.000000        NaN             actinopterygii   \n",
       "...          ...      ...         ...        ...                        ...   \n",
       "185921   2433785  2433250   13.206970        0.5  dhanbad sadar subdivision   \n",
       "185922   2433785  2433522   15.420900        0.5  dhanbad sadar subdivision   \n",
       "185923   2433785  2433549    9.231121        0.5  dhanbad sadar subdivision   \n",
       "185924   2433785  2433785   37.233094        1.0  dhanbad sadar subdivision   \n",
       "185925   2433785  2454548    9.047330        NaN  dhanbad sadar subdivision   \n",
       "\n",
       "                                                      doc  \n",
       "0       these actinopterygian fin rays attach directly...  \n",
       "1       even the acts of launching discharging artille...  \n",
       "2       state of nebraska as of the 2010 united states...  \n",
       "3       as of the 2010 united states census the cdp s ...  \n",
       "4       its lyrics were written by the buenos aires bo...  \n",
       "...                                                   ...  \n",
       "185921  one of the many spurs of pareshnath hill 1 365...  \n",
       "185922  the damodar river the most important river of ...  \n",
       "185923  while the damodar flows along the southern bou...  \n",
       "185924  initially the district was split into two subd...  \n",
       "185925  geographically garalbari is located in the lat...  \n",
       "\n",
       "[185926 rows x 6 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d31780-569d-4636-b0eb-363a13df95d6",
   "metadata": {},
   "source": [
    "# Recover BM25 scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "915235fb-2d8a-48e4-aaab-2016eb1ec215",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage/kliffeup/conda_envs/allknower/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n"
     ]
    }
   ],
   "source": [
    "import bm25s\n",
    "import Stemmer\n",
    "\n",
    "stemmer = Stemmer.Stemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d37bce88-4b49-45b2-b1a2-ccd4aad916d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'doc_id': 5, 'doc': 'he was the son of the nereid thetis and peleus king of phthia achilles most notable feat during the trojan war was the slaying of the trojan prince hector outside the gates of troy although the death of achilles is not presented in the iliad other sources concur that he was killed near the end of the trojan war by paris who shot him in the heel with an arrow later legends beginning with statius unfinished epic achilleid written in the 1st century ad state that achilles was invulnerable in all of his body except for his heel because when his mother thetis dipped him in the river styx as an infant she held him by one of his heels alluding to these legends the term achilles heel has come to mean a point of weakness especially in someone or something with an otherwise strong constitution the achilles tendon is also named after him due to these legends linear b tablets attest to the personal name achilleus in the forms a ki re u and a ki re we the latter being the dative of the former the name grew more popular even becoming common soon after the seventh century'}\n"
     ]
    }
   ],
   "source": [
    "for _, row in docs.iterrows():\n",
    "    print(dict(row))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce67af9-2459-4c29-9059-f9ba23c9789f",
   "metadata": {},
   "source": [
    "# Calc scores over whole doc corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b45387c0-5cae-43aa-9568-4c8cfdcf4aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_json = docs.apply(lambda row: dict(row), axis=1).values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "329e9108-59ba-4d5f-b0be-788f502ce0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_text = list(map(lambda item: item[\"doc\"], corpus_json))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "77290598-57de-43fb-a737-91c850068c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = bm25s.tokenization.Tokenizer(\n",
    "    stemmer=stemmer,\n",
    "    lower=True, # lowercase the tokens\n",
    "    stopwords=\"english\",  # or pass a list of stopwords\n",
    "    splitter=r\"\\w+\",  # by default r\"(?u)\\b\\w\\w+\\b\", can also be a function\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4ae074c6-0121-449f-b97f-0f762fb5b723",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                              \r"
     ]
    }
   ],
   "source": [
    "# Tokenize the corpus\n",
    "corpus_tokens = tokenizer.tokenize(\n",
    "    corpus_text, \n",
    "    update_vocab=True, # update the vocab as we tokenize\n",
    "    return_as=\"ids\"\n",
    ")\n",
    "\n",
    "# corpus_tokens = bm25s.tokenize(corpus_text, \n",
    "#                                # stopwords=\"en\", stemmer=stemmer\n",
    "#                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b74ef679-47e2-4b70-9d6f-8c4853d41ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = bm25s.BM25(corpus=corpus_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3f0358fb-d510-46af-92cd-89fe07675252",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                              \r"
     ]
    }
   ],
   "source": [
    "retriever.index(corpus_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5c53fd29-baa6-44ee-937f-b5fbdad3331f",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"actinopterygii\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "06abf6c0-9fe9-4375-b313-d8baa93dcb3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                              \r"
     ]
    }
   ],
   "source": [
    "query_tokens = tokenizer.tokenize(\n",
    "    [query], \n",
    "    update_vocab=False\n",
    ")\n",
    "\n",
    "# query_tokens = bm25s.tokenize(query,\n",
    "#                               stopwords=\"en\", stemmer=stemmer\n",
    "#                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8e4c0864-5ff5-4fb2-9491-58ba2682b75a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[850]]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# query_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "da92b99e-e9a1-4f03-abed-7600c7fc0d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# docs_79_query = data[data[\"query_id\"] == 79][[\"doc_id\", \"doc\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a8e5d351-2530-47ba-9ce8-2ed9b3b69577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus_79_json = docs_79_query.apply(lambda row: dict(row), axis=1).values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9c11947c-f0ef-47bc-8537-45e0d83b57c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus_79_text = list(map(lambda item: item[\"doc\"], corpus_79_json))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dd7fd4a3-52a0-438f-b858-58b367a0b54d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 146.17it/s]\n"
     ]
    }
   ],
   "source": [
    "# corpus_79_tokens = tokenizer.tokenize(\n",
    "#     corpus_79_text, \n",
    "#     update_vocab=False, # update the vocab as we tokenize\n",
    "#     return_as=\"ids\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ae7bffaf-55f7-44de-9a3e-43ce3cc7616e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus_79_text_ids = list(map(lambda item: retriever.corpus.index(item), corpus_79_json))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a97d1f9a-87be-42ed-962a-2bcb37646790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results, scores = retriever.retrieve(query_tokens, k=10, show_progress=False, return_as=\"tuple\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a908f671-b13d-4a42-a19c-d26d4e800b3e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# data[data[\"query_id\"] == 79][[\"doc_id\"]].values.flatten().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889a4e5c-e7be-44be-a23c-8687734941e0",
   "metadata": {},
   "source": [
    "# Calc BM25S scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2775ad5f-f47b-4e85-8dd8-1bc1fc879ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "11a40fe7-6d72-4320-8693-6a664996e2fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1444it [06:48,  3.53it/s]\n"
     ]
    }
   ],
   "source": [
    "for _, row in tqdm(queries.iterrows()):\n",
    "    query, query_id = row.query, row.query_id\n",
    "    \n",
    "    doc_ids_query = data[data[\"query_id\"] == query_id][[\"doc_id\"]].values.flatten().tolist()\n",
    "\n",
    "    query_tokens = tokenizer.tokenize(\n",
    "        [query], \n",
    "        update_vocab=False,\n",
    "        show_progress=False,\n",
    "    )\n",
    "    \n",
    "    results, scores = retriever.retrieve(query_tokens, k=len(corpus_json), show_progress=False)\n",
    "    doc_ids_results = list(map(lambda item: item[\"doc_id\"], results[0]))\n",
    "    doc_scores += [float(scores[0, doc_ids_results.index(doc_id)]) for doc_id in doc_ids_query]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0debc10-fe63-48df-9e1b-f755ebd6093d",
   "metadata": {},
   "source": [
    "# Calc pos statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "adccb573-c688-4ea1-921f-77f05cc69bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_query_token_ngram_coverage(query_tokens: list[int], doc_tokens: list[int], n: int = 1) -> int | float:\n",
    "    if n > min(len(query_tokens), len(doc_tokens)):\n",
    "        return 0\n",
    "\n",
    "    query_ngram_counter = {}\n",
    "    for i in range(len(query_tokens) - n + 1):\n",
    "        query_ngram_counter[tuple(query_tokens[i:i + n])] = 0\n",
    "\n",
    "    for i in range(len(doc_tokens) - n + 1):\n",
    "        doc_ngram = tuple(doc_tokens[i:i + n])\n",
    "        if doc_ngram in query_ngram_counter and query_ngram_counter[doc_ngram] == 0:\n",
    "            query_ngram_counter[doc_ngram] = 1\n",
    "\n",
    "    query_token_ngram_coverage = sum(query_ngram_counter.values())\n",
    "    return query_token_ngram_coverage, query_token_ngram_coverage / len(query_ngram_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d58e1881-f30e-4e01-a85c-609e366f9fc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_query_token_ngram_coverage([1, 2, 3], [1, 2, 4, 2, 4], n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4adbf9e1-7c96-462b-9803-448aa975f20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_doc_length(doc_tokens: list[int]) -> int:\n",
    "    return len(doc_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bb4a619c-cc27-4ac9-a4cc-418faa7d0f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_query_length(query_tokens: list[int]) -> int:\n",
    "    return len(query_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ccc374c6-b66c-412d-8c25-25dd8ad744e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_query_token_first_occurrence(query_tokens: list[int], doc_tokens: list[int]) -> int:\n",
    "    first_occurrence = len(doc_tokens)\n",
    "    \n",
    "    for i, doc_token in enumerate(doc_tokens):\n",
    "        if doc_token in query_tokens:\n",
    "            first_occurrence = i\n",
    "            break\n",
    "     \n",
    "    if normalize:\n",
    "        first_occurrence /= len(doc_tokens)\n",
    "\n",
    "    return first_occurrence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9da93471-6aba-4586-a6f6-f4690e808688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_query_token_first_occurrence([1, 2, 3], [4, 1, 4, 2, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f597f721-bdca-4d19-a226-64c6b348c1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_idf(\n",
    "    query_tokens: list[int], \n",
    "    docs_tokens: list[list[int]],\n",
    ") -> dict[int, int]:\n",
    "    query_tokens_counts_per_document = defaultdict(int)\n",
    "\n",
    "    for doc_tokens in docs_tokens:\n",
    "        doc_tokens_occurred_in_query = set()\n",
    "        for token in doc_tokens:\n",
    "            if token in query_tokens and token not in doc_tokens_occurred_in_query:\n",
    "                query_tokens_counts_per_document[token] += 1\n",
    "                doc_tokens_occurred_in_query.add(token)\n",
    "\n",
    "    num_documents = len(docs_tokens)\n",
    "    idf_dict = {}\n",
    "    for token, doc_count in query_tokens_counts_per_document.items():\n",
    "        idf_dict[token] = math.log(num_documents / (doc_count + 1)) + 1\n",
    "\n",
    "    return idf_dict\n",
    "\n",
    "\n",
    "def calc_hh_proximity(\n",
    "    query_tokens: list[int], \n",
    "    doc_tokens: list[list[int]], \n",
    "    idf_dict: dict[int, int], \n",
    "    z: float = 1.75,\n",
    ") -> float:\n",
    "    token_positions = defaultdict(list)\n",
    "    for idx, token in enumerate(doc_tokens):\n",
    "        if token in query_tokens:\n",
    "            token_positions[token].append(idx)\n",
    "\n",
    "    hh_proximity = 0\n",
    "\n",
    "    for cur_token, cur_token_positions in token_positions.items():\n",
    "        cur_token_idf = idf_dict.get(cur_token, 1)\n",
    "        for cur_token_position in cur_token_positions:\n",
    "            for other_token in query_tokens:\n",
    "                if other_token == cur_token:\n",
    "                    token_weight = 0.25\n",
    "                else:\n",
    "                    token_weight = 1\n",
    "                    \n",
    "                other_positions = token_positions.get(other_token, [])\n",
    "                \n",
    "                if other_positions:\n",
    "                    lmd = float(\"inf\")\n",
    "                    rmd = float(\"inf\")\n",
    "                    other_token_idf = idf_dict.get(other_token, 1)\n",
    "                    for other_position in other_positions:\n",
    "                        if other_position < cur_token_position:\n",
    "                            lmd = min(lmd, cur_token_position - other_position)\n",
    "                        elif other_position > cur_token_position:\n",
    "                            rmd = min(rmd, other_position - cur_token_position)\n",
    "                            break\n",
    "                    \n",
    "\n",
    "                    hh_proximity += token_weight * cur_token_idf * ((other_token_idf / (lmd ** z)) + (other_token_idf / (rmd ** z)))\n",
    "\n",
    "    return math.log(1 + hh_proximity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bf540db1-8658-4212-8186-4209cd68fb8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': 1.0, 'science': 1.0}\n",
      "HHProximity Score: {0.5839557466475039}\n"
     ]
    }
   ],
   "source": [
    "query_tokens = [\"data\", \"science\"]\n",
    "doc_tokens = [\"data\", \"is\", \"the\", \"new\", \"science\", \"of\", \"data\", \"analysis\"]\n",
    "docs_tokens = [\n",
    "    [\"data\", \"is\", \"the\", \"new\", \"science\", \"of\", \"data\", \"analysis\"],\n",
    "    [\"machine\", \"learning\", \"is\", \"a\", \"field\", \"of\", \"artificial\", \"intelligence\"],\n",
    "    [\"data\", \"science\", \"involves\", \"statistics\", \"and\", \"programming\"]\n",
    "]\n",
    "\n",
    "idf_dict = calc_idf(query_tokens, docs_tokens)\n",
    "print(idf_dict)\n",
    "hh_proximity_score = calc_hh_proximity(query_tokens, doc_tokens, idf_dict)\n",
    "print(f\"HHProximity Score:\", {hh_proximity_score})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8b54c0f1-35fc-4934-8474-39d1ba5f3dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_ids = docs[\"doc_id\"].values.tolist()\n",
    "features = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1513edc4-af9f-4b15-ab37-50272314583d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [01:58<00:00,  1.18s/it]\n"
     ]
    }
   ],
   "source": [
    "for query_id, row in tqdm(data.groupby(\"query_id\")):\n",
    "    query = row[\"query\"].values[0]\n",
    "\n",
    "    query_tokens = tokenizer.tokenize(\n",
    "        [query], \n",
    "        update_vocab=False,\n",
    "        show_progress=False,\n",
    "    )[0]\n",
    "\n",
    "    docs_tokens_query = list(map(lambda doc_id: corpus_tokens[doc_ids.index(doc_id)], row[\"doc_id\"].values))\n",
    "    # we can calculate idf from scratch by code line below\n",
    "    # but it is better to use fair idf scores from lucene and BM25 index\n",
    "    idf_dict = calc_idf(query_tokens, docs_tokens_query)\n",
    "\n",
    "    query_length = calc_query_length(query_tokens)\n",
    "\n",
    "    for doc_tokens in docs_tokens_query:\n",
    "        doc_length = calc_doc_length(doc_tokens)\n",
    "        query_token_first_occurrence_unnormalized, query_token_first_occurrence_normalized = calc_query_token_first_occurrence(\n",
    "            query_tokens, \n",
    "            doc_tokens,\n",
    "        )\n",
    "        query_token_last_occurrence_unnormalized, _ = calc_query_token_first_occurrence(\n",
    "            query_tokens, \n",
    "            doc_tokens[::-1],\n",
    "        )\n",
    "        query_token_last_occurrence_unnormalized = (doc_length - 1) - query_token_last_occurrence_unnormalized\n",
    "        query_token_last_occurrence_normalized = query_token_last_occurrence_unnormalized / doc_length\n",
    "        span_length_unnormalized = query_token_last_occurrence_unnormalized - query_token_first_occurrence_unnormalized + 1\n",
    "        span_length_normalized = span_length_unnormalized / doc_length\n",
    "        hh_proximity_score = calc_hh_proximity(query_tokens, doc_tokens, idf_dict)\n",
    "        \n",
    "        features.append(\n",
    "            [\n",
    "                hh_proximity_score,\n",
    "                query_length,\n",
    "                doc_length,\n",
    "                *calc_query_token_ngram_coverage(query_tokens, doc_tokens, n=1),\n",
    "                *calc_query_token_ngram_coverage(query_tokens, doc_tokens, n=2),\n",
    "                *calc_query_token_ngram_coverage(query_tokens, doc_tokens, n=3),\n",
    "                query_token_first_occurrence_unnormalized,\n",
    "                query_token_first_occurrence_normalized,\n",
    "                query_token_last_occurrence_unnormalized,\n",
    "                query_token_last_occurrence_normalized,\n",
    "                span_length_unnormalized,\n",
    "                span_length_normalized,\n",
    "            ]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3c82c79c-3e24-454c-9a3c-bcf85ac87791",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.DataFrame(\n",
    "    data=features,\n",
    "    columns=[\n",
    "        \"hh_proximity_score\",\n",
    "        \"query_length\",\n",
    "        \"doc_length\",\n",
    "        \"query_token_unigram_coverage_unnormalized\",\n",
    "        \"query_token_unigram_coverage_normalized\",\n",
    "        \"query_token_bigram_coverage_unnormalized\",\n",
    "        \"query_token_bigram_coverage_normalized\",\n",
    "        \"query_token_trigram_coverage_unnormalized\",\n",
    "        \"query_token_trigram_coverage_normalized\",\n",
    "        \"query_token_first_occurrence_unnormalized\",\n",
    "        \"query_token_first_occurrence_normalized\",\n",
    "        \"query_token_last_occurrence_unnormalized\",\n",
    "        \"query_token_last_occurrence_normalized\",\n",
    "        \"span_length_unnormalized\",\n",
    "        \"span_length_normalized\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "173e7148-9167-4830-8871-3316f4d54b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([data, features], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4968cda3-9b05-4d8a-9567-98496ef11a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fb3d7a29-0156-42f5-af72-d5a3657050c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['query_id', 'doc_id', 'relevance', 'query', 'doc', 'bm25_score',\n",
       "       'hh_proximity_score', 'query_length', 'doc_length',\n",
       "       'query_token_unigram_coverage_unnormalized',\n",
       "       'query_token_unigram_coverage_normalized',\n",
       "       'query_token_bigram_coverage_unnormalized',\n",
       "       'query_token_bigram_coverage_normalized',\n",
       "       'query_token_trigram_coverage_unnormalized',\n",
       "       'query_token_trigram_coverage_normalized',\n",
       "       'query_token_first_occurrence_unnormalized',\n",
       "       'query_token_first_occurrence_normalized',\n",
       "       'query_token_last_occurrence_unnormalized',\n",
       "       'query_token_last_occurrence_normalized', 'span_length_unnormalized',\n",
       "       'span_length_normalized'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "48e9c4dd-5738-428d-a8f5-4d2af94e32ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column_name in [\n",
    "    \"bm25_score\",\n",
    "    \"hh_proximity_score\",\n",
    "    \"query_length\",\n",
    "    \"doc_length\",\n",
    "    \"query_token_unigram_coverage_unnormalized\",\n",
    "    \"query_token_bigram_coverage_unnormalized\",\n",
    "    \"query_token_trigram_coverage_unnormalized\",\n",
    "    \"query_token_first_occurrence_unnormalized\",\n",
    "    \"query_token_last_occurrence_unnormalized\",\n",
    "    \"span_length_unnormalized\",\n",
    "]:\n",
    "    data[f\"{column_name}_max\"] = data.groupby(\"query_id\")[f\"{column_name}\"].transform(lambda item: item.max())\n",
    "    data[f\"{column_name}_min\"] = data.groupby(\"query_id\")[f\"{column_name}\"].transform(lambda item: item.min())\n",
    "    data[f\"{column_name}_mean\"] = data.groupby(\"query_id\")[f\"{column_name}\"].transform(lambda item: item.mean())\n",
    "    data[f\"{column_name}_median\"] = data.groupby(\"query_id\")[f\"{column_name}\"].transform(lambda item: item.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6c91722e-2ac0-4485-a6a4-a936f525c28e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['query_id', 'doc_id', 'relevance', 'query', 'doc', 'bm25_score',\n",
       "       'hh_proximity_score', 'query_length', 'doc_length',\n",
       "       'query_token_unigram_coverage_unnormalized',\n",
       "       'query_token_unigram_coverage_normalized',\n",
       "       'query_token_bigram_coverage_unnormalized',\n",
       "       'query_token_bigram_coverage_normalized',\n",
       "       'query_token_trigram_coverage_unnormalized',\n",
       "       'query_token_trigram_coverage_normalized',\n",
       "       'query_token_first_occurrence_unnormalized',\n",
       "       'query_token_first_occurrence_normalized',\n",
       "       'query_token_last_occurrence_unnormalized',\n",
       "       'query_token_last_occurrence_normalized', 'span_length_unnormalized',\n",
       "       'span_length_normalized', 'bm25_score_max', 'bm25_score_min',\n",
       "       'bm25_score_mean', 'bm25_score_median', 'hh_proximity_score_max',\n",
       "       'hh_proximity_score_min', 'hh_proximity_score_mean',\n",
       "       'hh_proximity_score_median', 'query_length_max', 'query_length_min',\n",
       "       'query_length_mean', 'query_length_median', 'doc_length_max',\n",
       "       'doc_length_min', 'doc_length_mean', 'doc_length_median',\n",
       "       'query_token_unigram_coverage_unnormalized_max',\n",
       "       'query_token_unigram_coverage_unnormalized_min',\n",
       "       'query_token_unigram_coverage_unnormalized_mean',\n",
       "       'query_token_unigram_coverage_unnormalized_median',\n",
       "       'query_token_bigram_coverage_unnormalized_max',\n",
       "       'query_token_bigram_coverage_unnormalized_min',\n",
       "       'query_token_bigram_coverage_unnormalized_mean',\n",
       "       'query_token_bigram_coverage_unnormalized_median',\n",
       "       'query_token_trigram_coverage_unnormalized_max',\n",
       "       'query_token_trigram_coverage_unnormalized_min',\n",
       "       'query_token_trigram_coverage_unnormalized_mean',\n",
       "       'query_token_trigram_coverage_unnormalized_median',\n",
       "       'query_token_first_occurrence_unnormalized_max',\n",
       "       'query_token_first_occurrence_unnormalized_min',\n",
       "       'query_token_first_occurrence_unnormalized_mean',\n",
       "       'query_token_first_occurrence_unnormalized_median',\n",
       "       'query_token_last_occurrence_unnormalized_max',\n",
       "       'query_token_last_occurrence_unnormalized_min',\n",
       "       'query_token_last_occurrence_unnormalized_mean',\n",
       "       'query_token_last_occurrence_unnormalized_median',\n",
       "       'span_length_unnormalized_max', 'span_length_unnormalized_min',\n",
       "       'span_length_unnormalized_mean', 'span_length_unnormalized_median'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9d7f652a-d1f4-41ce-98a3-2edf22002679",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\n",
    "    [\n",
    "        \"bm25_score\",\n",
    "        \"hh_proximity_score\",\n",
    "        \"query_length\",\n",
    "        \"doc_length\",\n",
    "        \"query_token_unigram_coverage_unnormalized\",\n",
    "        \"query_token_unigram_coverage_normalized\",\n",
    "        \"query_token_bigram_coverage_unnormalized\",\n",
    "        \"query_token_bigram_coverage_normalized\",\n",
    "        \"query_token_trigram_coverage_unnormalized\",\n",
    "        \"query_token_trigram_coverage_normalized\",\n",
    "        \"query_token_first_occurrence_unnormalized\",\n",
    "        \"query_token_first_occurrence_normalized\",\n",
    "        \"query_token_last_occurrence_unnormalized\",\n",
    "        \"query_token_last_occurrence_normalized\",\n",
    "        \"span_length_unnormalized\",\n",
    "        \"span_length_normalized\", \n",
    "        \"bm25_score_max\",\n",
    "        \"bm25_score_min\",\n",
    "        \"bm25_score_mean\",\n",
    "        \"bm25_score_median\",\n",
    "        \"hh_proximity_score_max\",\n",
    "        \"hh_proximity_score_min\",\n",
    "        \"hh_proximity_score_mean\",\n",
    "        \"hh_proximity_score_median\",\n",
    "        \"query_length_max\",\n",
    "        \"query_length_min\",\n",
    "        \"query_length_mean\",\n",
    "        \"query_length_median\",\n",
    "        \"doc_length_max\",\n",
    "        \"doc_length_min\",\n",
    "        \"doc_length_mean\",\n",
    "        \"doc_length_median\",\n",
    "        \"query_token_unigram_coverage_unnormalized_max\",\n",
    "        \"query_token_unigram_coverage_unnormalized_min\",\n",
    "        \"query_token_unigram_coverage_unnormalized_mean\",\n",
    "        \"query_token_unigram_coverage_unnormalized_median\",\n",
    "        \"query_token_bigram_coverage_unnormalized_max\",\n",
    "        \"query_token_bigram_coverage_unnormalized_min\",\n",
    "        \"query_token_bigram_coverage_unnormalized_mean\",\n",
    "        \"query_token_bigram_coverage_unnormalized_median\",\n",
    "        \"query_token_trigram_coverage_unnormalized_max\",\n",
    "        \"query_token_trigram_coverage_unnormalized_min\",\n",
    "        \"query_token_trigram_coverage_unnormalized_mean\",\n",
    "        \"query_token_trigram_coverage_unnormalized_median\",\n",
    "        \"query_token_first_occurrence_unnormalized_max\",\n",
    "        \"query_token_first_occurrence_unnormalized_min\",\n",
    "        \"query_token_first_occurrence_unnormalized_mean\",\n",
    "        \"query_token_first_occurrence_unnormalized_median\",\n",
    "        \"query_token_last_occurrence_unnormalized_max\",\n",
    "        \"query_token_last_occurrence_unnormalized_min\",\n",
    "        \"query_token_last_occurrence_unnormalized_mean\",\n",
    "        \"query_token_last_occurrence_unnormalized_median\",\n",
    "        \"span_length_unnormalized_max\",\n",
    "        \"span_length_unnormalized_min\",\n",
    "        \"span_length_unnormalized_mean\",\n",
    "        \"span_length_unnormalized_median\",\n",
    "        \"doc_id\",\n",
    "        \"query_id\",\n",
    "        \"relevance\",\n",
    "    ]\n",
    "].to_csv(f\"{DATASET_PREFIX}_{DATASET_VERSION}_{STAGE}_preprocessed_light_v2.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06881a91-7a93-408e-963c-0577d8f3addc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
